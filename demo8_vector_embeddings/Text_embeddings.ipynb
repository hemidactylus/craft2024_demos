{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d3a60f-63f8-4b5d-9319-c49ee44ca561",
   "metadata": {},
   "source": [
    "# Demo 8 - Text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc24b5-a5c3-40cb-9a5b-54a7fa7f122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"python-dotenv>=1.0.0\" \"sentence_transformers>=2.7.0\" \"openai>=1.30.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29571f-fffc-4ea0-bc21-278138454550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d1ffe-d4a0-4fa0-8256-8e26157a7d39",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bd305-754e-4461-ab65-6810c973224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_norm(v):\n",
    "    return sum(v_i * v_i for v_i in v) ** 0.5\n",
    "\n",
    "def normalize_vector(v):\n",
    "    norm = vector_norm(v)\n",
    "    return [ v_i / norm for v_i in v]\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    nv1 = normalize_vector(v1)\n",
    "    nv2 = normalize_vector(v2)\n",
    "    dot_product = sum(v1_i * v2_i for v1_i, v2_i in zip(nv1, nv2))\n",
    "    return (1 + dot_product) / 2\n",
    "\n",
    "\n",
    "print(f\"vector_norm([3, 4]) = {vector_norm([3, 4])}\")\n",
    "print(f\"normalize_vector([3, 4]) = {normalize_vector([3, 4])}\")\n",
    "print(f\"cosine_sim([10, 0], [3, 0]) = {cosine_sim([10, 0], [3, 0])}\")\n",
    "print(f\"cosine_sim([4, 0], [0, 5]) = {cosine_sim([4, 0], [0, 5])}\")\n",
    "print(f\"cosine_sim([91, 0], [-16, 0]) = {cosine_sim([91, 0], [-16, 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596940-0a2d-4f8a-be46-6a113052d1e0",
   "metadata": {},
   "source": [
    "## HuggingFace local embedding model\n",
    "\n",
    "_Note: the next cell, on its first run, mayu take some time to download all required assets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04ed1d-fa05-4485-8c34-f52ebaf17075",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = SentenceTransformer(\"paraphrase-albert-small-v2\")\n",
    "\n",
    "def get_hf_embeddings(texts):\n",
    "    raw_vectors = hf_model.encode(texts)\n",
    "    # This model returns NON-NORMALIZED vectors: they need to be normalized:\n",
    "    return [normalize_vector(raw_vector) for raw_vector in raw_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc40bc-4aff-42a5-9fbf-696f5641a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"At dawn, the pond fills with dragonflies, frogs, and all sorts of critters.\",\n",
    "    \"The deep roots of this oak can reach the tiniest amount of stored water.\",\n",
    "    \"When plate tectonics was first proposed, not many took it seriously.\",\n",
    "    \"Look closely and you'll notice that these 'twigs' are in fact weird insects...\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454ad44-d68c-4125-879a-960b0c289058",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embeddings = get_hf_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ca7ed-3597-4a11-9bbc-deb59b93b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(HuggingFace) embedding of first sentence:\")\n",
    "hf_vector0 = hf_embeddings[0]\n",
    "print(f\"    {str(hf_vector0)[:64]} ... ({len(hf_vector0)} numbers)\")\n",
    "print(f\"Norm = {vector_norm(hf_vector0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afb056-76cd-45db-85d0-778dd9507907",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe5792-92ea-4ee1-950c-419e02537368",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(HuggingFace) similarities to '{sentences[0][:24]}...':\")\n",
    "for hf_vector, sentence in zip(hf_embeddings, sentences):\n",
    "    sim = cosine_sim(hf_vector0, hf_vector)\n",
    "    print(f\"  sim={sim:.3f} '{sentence[:24]}...''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8868bb1-a4a0-4d42-b7b7-51600334106b",
   "metadata": {},
   "source": [
    "## OpenAI embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51f4a9-0027-41b2-94a0-6bbd69bef560",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Please input your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4480e-e1f1-4ac5-8f6d-055266f0502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "def get_openai_embeddings(texts):\n",
    "    api_response = client.embeddings.create(input=texts, model=\"text-embedding-ada-002\")\n",
    "    return [r.embedding for r in api_response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe907f0-b205-4000-a6c2-9dbc120bbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings = get_openai_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f590b-acd7-4ead-9210-606077132255",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(openAI) embedding of first sentence:\")\n",
    "openai_vector0 = openai_embeddings[0]\n",
    "print(f\"    {str(openai_vector0)[:64]} ... ({len(openai_vector0)} numbers)\")\n",
    "print(f\"Norm = {vector_norm(openai_vector0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77128a17-8658-436b-9f03-7ae7648a879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(openAI) similarities to '{sentences[0][:24]}...':\")\n",
    "for openai_vector, sentence in zip(openai_embeddings, sentences):\n",
    "    sim = cosine_sim(openai_vector0, openai_vector)\n",
    "    print(f\"  sim={sim:.3f} '{sentence[:24]}...''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32713e51-3fab-49bb-b17e-8633665c2bd5",
   "metadata": {},
   "source": [
    "### Randomness!\n",
    "\n",
    "(A little effect, but it may bring nasty surprises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46cbc1b-bf1c-4780-b632-52c4a0d83f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_openai_embeddings([\"This is always the same text.\"] * 40)\n",
    "\n",
    "for result in results:\n",
    "    print(cosine_sim(results[0], result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a06e3-9898-4861-98ec-5269795f09c4",
   "metadata": {},
   "source": [
    "## The Cone\n",
    "\n",
    "(this uses OpenAI's embeddings right now, but can be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48558482-060b-40fb-ba5d-9dba58376427",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = [\n",
    "    \"Whereof one cannot speak, thereof one must be silent.\",\n",
    "    \"The world is the totality of facts, not of things.\",\n",
    "    \"I was so amazed to find out he accepted to have dinner with me!\",\n",
    "    \"Gh gh gh ghghgh bo bobobobobo bobobo\",\n",
    "    # note the tiny difference just on the last 'word':\n",
    "    \"Gh gh gh ghghgh bo bobobobobo bababa\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41333c4-b210-4f4d-9ddb-c432184e185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings2 = get_openai_embeddings(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c52303-ddd5-47a9-916e-49416fe8b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table header:\n",
    "print(\"     \", end=\"\")\n",
    "for emb_b_i in range(len(openai_embeddings2)):\n",
    "    print(f\"  {emb_b_i:<5}\", end=\"\")\n",
    "print(\"\")\n",
    "#\n",
    "for emb_a_i, (emb_a, sentence_a) in enumerate(zip(openai_embeddings2, sentences2)):\n",
    "    print(f\"{emb_a_i:<4}:\", end=\"\")\n",
    "    for emb_b in openai_embeddings2:\n",
    "        sim = cosine_sim(emb_a, emb_b)\n",
    "        print(f\"  {sim:0.3f}\", end=\"\")\n",
    "    print(f\"      ({sentence_a[:16]} ... {sentence_a[-16:]})\", end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ad0d6-e3ca-46be-91e9-162e23e235b1",
   "metadata": {},
   "source": [
    "#### In other words ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccbdae-01b8-4e51-a6a0-52945caede0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sim(text1, text2):\n",
    "    emb1, emb2 = get_openai_embeddings([text1, text2])\n",
    "    return cosine_sim(emb1, emb2)\n",
    "\n",
    "print(text_sim(\"Ghghgh kokoko\", \"Ghghgh kokoky\"))\n",
    "print(text_sim(\"Something that makes sense\", \"Ghghgh kokoky\"))\n",
    "print(text_sim(\"Something that makes sense\", \"This sentence is largely unrelated to the previous\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275d86e-9639-4a6a-a169-d0bdb305e6ed",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
